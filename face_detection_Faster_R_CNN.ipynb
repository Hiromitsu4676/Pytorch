{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "face_detection_Faster_R_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1SJ_WQmL4HsrcDiKaTMw1FNrlODFp4w38",
      "authorship_tag": "ABX9TyPBpwokhPgSgl+e1Xcw+djI",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4bffaf93577e499c99967618f1f98b4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9eea31094159482cb2416a5cafa0d28e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_239f4386b7ad4b1da5784495b3a54f6b",
              "IPY_MODEL_8d1f9398159344c1bdb30c90a015ac1d",
              "IPY_MODEL_c8f2dc946ab24ec59c083fb092fc2f7f"
            ]
          }
        },
        "9eea31094159482cb2416a5cafa0d28e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "239f4386b7ad4b1da5784495b3a54f6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_368e34449e4c4c7f97ecb245761498bc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8c4a2988072e4887845aa7de9d9854c8"
          }
        },
        "8d1f9398159344c1bdb30c90a015ac1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_416e7e9b91334aad8ed0e9a14a1c7b0a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 102530333,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 102530333,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1a503afbda0d4b6cbea39297badf7a2c"
          }
        },
        "c8f2dc946ab24ec59c083fb092fc2f7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cc66691d4aaf4b9b854f16f6ea3b3ce0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 97.8M/97.8M [00:00&lt;00:00, 139MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_71b33484f340468fb64904ec2029d550"
          }
        },
        "368e34449e4c4c7f97ecb245761498bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8c4a2988072e4887845aa7de9d9854c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "416e7e9b91334aad8ed0e9a14a1c7b0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1a503afbda0d4b6cbea39297badf7a2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cc66691d4aaf4b9b854f16f6ea3b3ce0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "71b33484f340468fb64904ec2029d550": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hiromitsu4676/Pytorch/blob/main/face_detection_Faster_R_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGrp8HyE4l2S",
        "outputId": "e32d972e-96bf-4388-921d-25638c65a483"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-2.10.0-py3-none-any.whl (308 kB)\n",
            "\u001b[K     |████████████████████████████████| 308 kB 12.8 MB/s \n",
            "\u001b[?25hCollecting alembic\n",
            "  Downloading alembic-1.7.6-py3-none-any.whl (210 kB)\n",
            "\u001b[K     |████████████████████████████████| 210 kB 50.3 MB/s \n",
            "\u001b[?25hCollecting colorlog\n",
            "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.63.0)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Collecting cliff\n",
            "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 5.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.21.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (3.13)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.31)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.7)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.11.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.2)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.1.6-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 4.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (5.4.0)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.1.1)\n",
            "Collecting autopage>=0.4.0\n",
            "  Downloading autopage-0.5.0-py3-none-any.whl (29 kB)\n",
            "Collecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.4.0-py3-none-any.whl (150 kB)\n",
            "\u001b[K     |████████████████████████████████| 150 kB 38.9 MB/s \n",
            "\u001b[?25hCollecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.8.1-py2.py3-none-any.whl (113 kB)\n",
            "\u001b[K     |████████████████████████████████| 113 kB 37.6 MB/s \n",
            "\u001b[?25hCollecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 6.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (3.10.0.2)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=1d6e49b05529109dfea3cfa109422aaff9313902f1252156dcb6913639bfebd9\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
            "Successfully installed Mako-1.1.6 alembic-1.7.6 autopage-0.5.0 cliff-3.10.1 cmaes-0.8.2 cmd2-2.4.0 colorlog-6.6.0 optuna-2.10.0 pbr-5.8.1 pyperclip-1.8.2 stevedore-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda, Compose\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import optuna\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import xml.etree.ElementTree as ET \n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor"
      ],
      "metadata": {
        "id": "-mfiU3INzBCm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AH2pNNYhutj",
        "outputId": "b52051d4-c8d1-44d9-b47a-9ee153ea33f1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Xml2List(object):\n",
        "    \n",
        "    def __init__(self, classes):\n",
        "        self.classes = classes\n",
        "        \n",
        "    def __call__(self, xml_path):\n",
        "        \n",
        "        ret = []\n",
        "        \n",
        "        xml = ET.parse(xml_path).getroot()\n",
        "        \n",
        "        for size in xml.iter(\"size\"):\n",
        "          \n",
        "            width = float(size.find(\"width\").text)\n",
        "            height = float(size.find(\"height\").text)\n",
        "                \n",
        "        for obj in xml.iter(\"object\"):\n",
        "            \n",
        "            difficult = int(obj.find(\"difficult\").text)\n",
        "            if difficult == 1:\n",
        "                continue\n",
        "                \n",
        "            bndbox = [width, height]\n",
        "            \n",
        "            name = obj.find(\"name\").text.lower().strip() \n",
        "            bbox = obj.find(\"bndbox\") \n",
        "            \n",
        "            pts = [\"xmin\", \"ymin\", \"xmax\", \"ymax\"]\n",
        "            \n",
        "            for pt in pts:\n",
        "                \n",
        "                cur_pixel =  float(bbox.find(pt).text)\n",
        "                    \n",
        "                bndbox.append(cur_pixel)\n",
        "                \n",
        "            label_idx = self.classes.index(name)\n",
        "            bndbox.append(label_idx)\n",
        "            \n",
        "            ret += [bndbox]\n",
        "            \n",
        "        return np.array(ret) # [width, height, xmin, ymin, xamx, ymax, label_idx]"
      ],
      "metadata": {
        "id": "UqO6miTDzz7S"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#trainのanotationの読み込み\n",
        "xml_paths = glob.glob(\"./drive/MyDrive/Pytorch/privateDataset/xml_resize/*.xml\")\n",
        "classes = [\"saito\", \"ohnaka\",\"doi\",'sugai','suzuki']\n",
        "    \n",
        "transform_anno = Xml2List(classes)\n",
        "\n",
        "df = pd.DataFrame(columns=[\"image_id\", \"width\", \"height\", \"xmin\", \"ymin\", \"xmax\", \"ymax\", \"class\"])\n",
        "\n",
        "for path in xml_paths:\n",
        "    image_id = path.split(\"/\")[-1].split(\".\")[0]\n",
        "    bboxs = transform_anno(path)\n",
        "\n",
        "    for bbox in bboxs:\n",
        "        tmp = pd.Series(bbox, index=[\"width\", \"height\", \"xmin\", \"ymin\", \"xmax\", \"ymax\", \"class\"])\n",
        "        tmp[\"image_id\"] = image_id\n",
        "        df = df.append(tmp, ignore_index=True)\n",
        "\n",
        "df = df.sort_values(by=\"image_id\", ascending=True)\n",
        "\n",
        "\n",
        "#valのanotationの読み込み\n",
        "xml_paths=glob.glob(\"./drive/MyDrive/Pytorch/privateDataset/xml_resize/*.xml\")\n",
        "\n",
        "classes = [\"saito\", \"ohnaka\",\"doi\",'sugai','suzuki']\n",
        "\n",
        "\n",
        "transform_anno = Xml2List(classes)\n",
        "\n",
        "df_val = pd.DataFrame(columns=[\"image_id\", \"width\", \"height\", \"xmin\", \"ymin\", \"xmax\", \"ymax\", \"class\"])\n",
        "\n",
        "for path in xml_paths:\n",
        "    image_id = path.split(\"/\")[-1].split(\".\")[0]\n",
        "    bboxs = transform_anno(path)\n",
        "\n",
        "    for bbox in bboxs:\n",
        "        tmp = pd.Series(bbox, index=[\"width\", \"height\", \"xmin\", \"ymin\", \"xmax\", \"ymax\", \"class\"])\n",
        "        tmp[\"image_id\"] = image_id\n",
        "        df_val = df_val.append(tmp, ignore_index=True)\n",
        "\n",
        "df_val = df_val.sort_values(by=\"image_id\", ascending=True)"
      ],
      "metadata": {
        "id": "LAqN3JnQdHIi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 背景のクラス（0）が必要のため、ラベルは1スタートにする\n",
        "df[\"class\"] = df[\"class\"] + 1"
      ],
      "metadata": {
        "id": "R3NGh_T2eBl3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(torch.utils.data.Dataset):\n",
        "    \n",
        "    def __init__(self, df, image_dir):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.image_ids = df[\"image_id\"].unique()\n",
        "        self.df = df\n",
        "        self.image_dir = image_dir\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        " \n",
        "        transform = transforms.Compose([\n",
        "                                        transforms.ToTensor()\n",
        "        ])\n",
        "\n",
        "        # 入力画像の読み込み\n",
        "        image_id = self.image_ids[index]\n",
        "        image = Image.open(f\"{self.image_dir}/{image_id}.jpg\")\n",
        "        image = transform(image)\n",
        "        \n",
        "        # アノテーションデータの読み込み\n",
        "        records = self.df[self.df[\"image_id\"] == image_id]\n",
        "        boxes = torch.tensor(records[[\"xmin\", \"ymin\", \"xmax\", \"ymax\"]].values.astype(np.float32), dtype=torch.float32)\n",
        "        \n",
        "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
        "        area = torch.as_tensor(area, dtype=torch.float32)\n",
        "        \n",
        "        labels = torch.tensor(records[\"class\"].values.astype(np.int64), dtype=torch.int64)\n",
        "        \n",
        "        iscrowd = torch.zeros((records.shape[0], ), dtype=torch.int64)\n",
        "        \n",
        "        target = {}\n",
        "        target[\"boxes\"] = boxes\n",
        "        target[\"labels\"]= labels\n",
        "        target[\"image_id\"] = torch.tensor([index])\n",
        "        target[\"area\"] = area\n",
        "        target[\"iscrowd\"] = iscrowd\n",
        "\n",
        "\n",
        "        return image, target, image_id\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.image_ids.shape[0]"
      ],
      "metadata": {
        "id": "gW2rBMW51w4U"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_dir1=\"./drive/MyDrive/Pytorch/privateDataset/img_resize\"\n",
        "dataset = MyDataset(df, image_dir1)\n",
        "\n",
        "image_dir2=\"./drive/MyDrive/Pytorch/privateDataset/img_resize\"\n",
        "dataset_val = MyDataset(df_val, image_dir2)"
      ],
      "metadata": {
        "id": "3M3t7BGpds2e"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#データのロード\n",
        "torch.manual_seed(2020)\n",
        "\n",
        "train=dataset\n",
        "val=dataset_val\n",
        "\n",
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=False, collate_fn=collate_fn)\n",
        "val_dataloader = torch.utils.data.DataLoader(val, batch_size=10, shuffle=False, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "c2DMrM5dd4YZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#モデルの作成\n",
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=False)####True\n",
        "\n",
        "##注意　クラス数＋１\n",
        "num_classes = (len(classes)) + 1\n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)"
      ],
      "metadata": {
        "id": "tcp6JAhRzVTR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "4bffaf93577e499c99967618f1f98b4d",
            "9eea31094159482cb2416a5cafa0d28e",
            "239f4386b7ad4b1da5784495b3a54f6b",
            "8d1f9398159344c1bdb30c90a015ac1d",
            "c8f2dc946ab24ec59c083fb092fc2f7f",
            "368e34449e4c4c7f97ecb245761498bc",
            "8c4a2988072e4887845aa7de9d9854c8",
            "416e7e9b91334aad8ed0e9a14a1c7b0a",
            "1a503afbda0d4b6cbea39297badf7a2c",
            "cc66691d4aaf4b9b854f16f6ea3b3ce0",
            "71b33484f340468fb64904ec2029d550"
          ]
        },
        "outputId": "4dccd807-1dde-4b75-bfb5-ffc7a84457de"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4bffaf93577e499c99967618f1f98b4d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##学習\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
        "num_epochs = 50\n",
        "\n",
        "#GPUのキャッシュクリア\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "model.cuda()\n",
        "\n",
        "model.train()#学習モードに移行\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    for i, batch in enumerate(train_dataloader):\n",
        "\n",
        "        images, targets, image_ids = batch#####　batchはそのミニバッジのimage、tagets,image_idsが入ってる\n",
        "\n",
        "        images = list(image.to(device) for image in images)\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        ##学習モードでは画像とターゲット（ground-truth）を入力する\n",
        "        ##返り値はdict[tensor]でlossが入ってる。（RPNとRCNN両方のloss）\n",
        "        loss_dict= model(images, targets)\n",
        "\n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "        loss_value = losses.item()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        losses.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 5 == 0:\n",
        "          print(f\"epoch #{epoch+1} Iteration #{i+1} loss: {loss_value}\")  \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1W8yoPn0ZRl",
        "outputId": "70421ce2-7980-4ffd-ed1c-e323827cfdb4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch #1 Iteration #5 loss: 1.0612683296203613\n",
            "epoch #1 Iteration #10 loss: 0.8356747031211853\n",
            "epoch #1 Iteration #15 loss: 0.45288655161857605\n",
            "epoch #2 Iteration #5 loss: 0.29418039321899414\n",
            "epoch #2 Iteration #10 loss: 0.6652355790138245\n",
            "epoch #2 Iteration #15 loss: 0.6425930261611938\n",
            "epoch #3 Iteration #5 loss: 0.25981202721595764\n",
            "epoch #3 Iteration #10 loss: 0.5255500078201294\n",
            "epoch #3 Iteration #15 loss: 0.41766297817230225\n",
            "epoch #4 Iteration #5 loss: 0.2097332626581192\n",
            "epoch #4 Iteration #10 loss: 0.48117929697036743\n",
            "epoch #4 Iteration #15 loss: 0.3991867005825043\n",
            "epoch #5 Iteration #5 loss: 0.20416566729545593\n",
            "epoch #5 Iteration #10 loss: 0.42550399899482727\n",
            "epoch #5 Iteration #15 loss: 0.39205849170684814\n",
            "epoch #6 Iteration #5 loss: 0.13957682251930237\n",
            "epoch #6 Iteration #10 loss: 0.3497893810272217\n",
            "epoch #6 Iteration #15 loss: 0.35967808961868286\n",
            "epoch #7 Iteration #5 loss: 0.13027513027191162\n",
            "epoch #7 Iteration #10 loss: 0.330314040184021\n",
            "epoch #7 Iteration #15 loss: 0.3823998272418976\n",
            "epoch #8 Iteration #5 loss: 0.142547607421875\n",
            "epoch #8 Iteration #10 loss: 0.40996092557907104\n",
            "epoch #8 Iteration #15 loss: 0.3329651355743408\n",
            "epoch #9 Iteration #5 loss: 0.13199500739574432\n",
            "epoch #9 Iteration #10 loss: 0.3629049062728882\n",
            "epoch #9 Iteration #15 loss: 0.3728379011154175\n",
            "epoch #10 Iteration #5 loss: 0.1247696503996849\n",
            "epoch #10 Iteration #10 loss: 0.3394191265106201\n",
            "epoch #10 Iteration #15 loss: 0.4668081998825073\n",
            "epoch #11 Iteration #5 loss: 0.12215681374073029\n",
            "epoch #11 Iteration #10 loss: 0.33850234746932983\n",
            "epoch #11 Iteration #15 loss: 0.35773974657058716\n",
            "epoch #12 Iteration #5 loss: 0.10982635617256165\n",
            "epoch #12 Iteration #10 loss: 0.2973351776599884\n",
            "epoch #12 Iteration #15 loss: 0.3481793999671936\n",
            "epoch #13 Iteration #5 loss: 0.11590119451284409\n",
            "epoch #13 Iteration #10 loss: 0.36677032709121704\n",
            "epoch #13 Iteration #15 loss: 0.40861427783966064\n",
            "epoch #14 Iteration #5 loss: 0.11254017800092697\n",
            "epoch #14 Iteration #10 loss: 0.2577292323112488\n",
            "epoch #14 Iteration #15 loss: 0.35371914505958557\n",
            "epoch #15 Iteration #5 loss: 0.13721925020217896\n",
            "epoch #15 Iteration #10 loss: 0.3438412547111511\n",
            "epoch #15 Iteration #15 loss: 0.3809548020362854\n",
            "epoch #16 Iteration #5 loss: 0.10966023802757263\n",
            "epoch #16 Iteration #10 loss: 0.26990216970443726\n",
            "epoch #16 Iteration #15 loss: 0.3025379776954651\n",
            "epoch #17 Iteration #5 loss: 0.11174596101045609\n",
            "epoch #17 Iteration #10 loss: 0.29483455419540405\n",
            "epoch #17 Iteration #15 loss: 0.2926149070262909\n",
            "epoch #18 Iteration #5 loss: 0.10188499838113785\n",
            "epoch #18 Iteration #10 loss: 0.3126053512096405\n",
            "epoch #18 Iteration #15 loss: 0.2445351481437683\n",
            "epoch #19 Iteration #5 loss: 0.11891068518161774\n",
            "epoch #19 Iteration #10 loss: 0.2934701442718506\n",
            "epoch #19 Iteration #15 loss: 0.3091142773628235\n",
            "epoch #20 Iteration #5 loss: 0.13625416159629822\n",
            "epoch #20 Iteration #10 loss: 0.22024677693843842\n",
            "epoch #20 Iteration #15 loss: 0.30526694655418396\n",
            "epoch #21 Iteration #5 loss: 0.09888984262943268\n",
            "epoch #21 Iteration #10 loss: 0.28672707080841064\n",
            "epoch #21 Iteration #15 loss: 0.2667746841907501\n",
            "epoch #22 Iteration #5 loss: 0.10212423652410507\n",
            "epoch #22 Iteration #10 loss: 0.2125948965549469\n",
            "epoch #22 Iteration #15 loss: 0.2326827347278595\n",
            "epoch #23 Iteration #5 loss: 0.10548214614391327\n",
            "epoch #23 Iteration #10 loss: 0.2057236284017563\n",
            "epoch #23 Iteration #15 loss: 0.2575363516807556\n",
            "epoch #24 Iteration #5 loss: 0.09139811992645264\n",
            "epoch #24 Iteration #10 loss: 0.23712560534477234\n",
            "epoch #24 Iteration #15 loss: 0.23854263126850128\n",
            "epoch #25 Iteration #5 loss: 0.08321399986743927\n",
            "epoch #25 Iteration #10 loss: 0.3080771863460541\n",
            "epoch #25 Iteration #15 loss: 0.21956902742385864\n",
            "epoch #26 Iteration #5 loss: 0.07499987632036209\n",
            "epoch #26 Iteration #10 loss: 0.21336400508880615\n",
            "epoch #26 Iteration #15 loss: 0.2447279542684555\n",
            "epoch #27 Iteration #5 loss: 0.10143622756004333\n",
            "epoch #27 Iteration #10 loss: 0.17697079479694366\n",
            "epoch #27 Iteration #15 loss: 0.23762573301792145\n",
            "epoch #28 Iteration #5 loss: 0.08464229851961136\n",
            "epoch #28 Iteration #10 loss: 0.18770824372768402\n",
            "epoch #28 Iteration #15 loss: 0.2397974133491516\n",
            "epoch #29 Iteration #5 loss: 0.09385555982589722\n",
            "epoch #29 Iteration #10 loss: 0.270465612411499\n",
            "epoch #29 Iteration #15 loss: 0.24330921471118927\n",
            "epoch #30 Iteration #5 loss: 0.07122120261192322\n",
            "epoch #30 Iteration #10 loss: 0.23145148158073425\n",
            "epoch #30 Iteration #15 loss: 0.22637954354286194\n",
            "epoch #31 Iteration #5 loss: 0.06422648578882217\n",
            "epoch #31 Iteration #10 loss: 0.1787375956773758\n",
            "epoch #31 Iteration #15 loss: 0.22288669645786285\n",
            "epoch #32 Iteration #5 loss: 0.07999897748231888\n",
            "epoch #32 Iteration #10 loss: 0.19423095881938934\n",
            "epoch #32 Iteration #15 loss: 0.1685439497232437\n",
            "epoch #33 Iteration #5 loss: 0.06334787607192993\n",
            "epoch #33 Iteration #10 loss: 0.1848733276128769\n",
            "epoch #33 Iteration #15 loss: 0.16926468908786774\n",
            "epoch #34 Iteration #5 loss: 0.05984994024038315\n",
            "epoch #34 Iteration #10 loss: 0.1301828920841217\n",
            "epoch #34 Iteration #15 loss: 0.1656695008277893\n",
            "epoch #35 Iteration #5 loss: 0.05774252116680145\n",
            "epoch #35 Iteration #10 loss: 0.13165535032749176\n",
            "epoch #35 Iteration #15 loss: 0.16419067978858948\n",
            "epoch #36 Iteration #5 loss: 0.07165641337633133\n",
            "epoch #36 Iteration #10 loss: 0.1799812763929367\n",
            "epoch #36 Iteration #15 loss: 0.16114147007465363\n",
            "epoch #37 Iteration #5 loss: 0.0770062729716301\n",
            "epoch #37 Iteration #10 loss: 0.16904020309448242\n",
            "epoch #37 Iteration #15 loss: 0.13804051280021667\n",
            "epoch #38 Iteration #5 loss: 0.0637797862291336\n",
            "epoch #38 Iteration #10 loss: 0.17482085525989532\n",
            "epoch #38 Iteration #15 loss: 0.12074300646781921\n",
            "epoch #39 Iteration #5 loss: 0.059785012155771255\n",
            "epoch #39 Iteration #10 loss: 0.19098372757434845\n",
            "epoch #39 Iteration #15 loss: 0.15073926746845245\n",
            "epoch #40 Iteration #5 loss: 0.07605862617492676\n",
            "epoch #40 Iteration #10 loss: 0.1214490532875061\n",
            "epoch #40 Iteration #15 loss: 0.141209676861763\n",
            "epoch #41 Iteration #5 loss: 0.049869354814291\n",
            "epoch #41 Iteration #10 loss: 0.16705487668514252\n",
            "epoch #41 Iteration #15 loss: 0.12746669352054596\n",
            "epoch #42 Iteration #5 loss: 0.050220075994729996\n",
            "epoch #42 Iteration #10 loss: 0.13592232763767242\n",
            "epoch #42 Iteration #15 loss: 0.14538618922233582\n",
            "epoch #43 Iteration #5 loss: 0.05317215994000435\n",
            "epoch #43 Iteration #10 loss: 0.12014836817979813\n",
            "epoch #43 Iteration #15 loss: 0.15019966661930084\n",
            "epoch #44 Iteration #5 loss: 0.05543416738510132\n",
            "epoch #44 Iteration #10 loss: 0.11708115041255951\n",
            "epoch #44 Iteration #15 loss: 0.15292274951934814\n",
            "epoch #45 Iteration #5 loss: 0.054712869226932526\n",
            "epoch #45 Iteration #10 loss: 0.1721564680337906\n",
            "epoch #45 Iteration #15 loss: 0.14107809960842133\n",
            "epoch #46 Iteration #5 loss: 0.06449045240879059\n",
            "epoch #46 Iteration #10 loss: 0.1218670904636383\n",
            "epoch #46 Iteration #15 loss: 0.1343204826116562\n",
            "epoch #47 Iteration #5 loss: 0.03933471813797951\n",
            "epoch #47 Iteration #10 loss: 0.14370226860046387\n",
            "epoch #47 Iteration #15 loss: 0.12350643426179886\n",
            "epoch #48 Iteration #5 loss: 0.05396940931677818\n",
            "epoch #48 Iteration #10 loss: 0.11926352977752686\n",
            "epoch #48 Iteration #15 loss: 0.11121711879968643\n",
            "epoch #49 Iteration #5 loss: 0.054112810641527176\n",
            "epoch #49 Iteration #10 loss: 0.12771153450012207\n",
            "epoch #49 Iteration #15 loss: 0.11625991016626358\n",
            "epoch #50 Iteration #5 loss: 0.04179202392697334\n",
            "epoch #50 Iteration #10 loss: 0.11180620640516281\n",
            "epoch #50 Iteration #15 loss: 0.09793652594089508\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#結果の表示\n",
        "def show(val_dataloader):\n",
        "    import matplotlib.pyplot as plt\n",
        "    from PIL import ImageDraw, ImageFont\n",
        "    from PIL import Image\n",
        "\n",
        "    #GPUのキャッシュクリア\n",
        "    import torch\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')  \n",
        "    model.to(device)\n",
        "    model.eval()#推論モードへ\n",
        "\n",
        "    images, targets, image_ids = next(iter(val_dataloader))\n",
        "\n",
        "    images = list(img.to(device) for img in images)\n",
        "\n",
        "    #推論時は予測を返す\n",
        "    '''\n",
        "     - boxes (FloatTensor[N, 4]): the predicted boxes in [x1, y1, x2, y2] format, with values of x\n",
        "          between 0 and W and values of y between 0 and H\n",
        "        - labels (Int64Tensor[N]): the predicted labels for each image\n",
        "        - scores (Tensor[N]): the scores or each prediction\n",
        "    '''\n",
        "    outputs = model(images)\n",
        "\n",
        "    for i, image in enumerate(images):\n",
        "\n",
        "        image = image.permute(1, 2, 0).cpu().numpy()\n",
        "        image = Image.fromarray((image * 255).astype(np.uint8))\n",
        "\n",
        "        boxes = outputs[i][\"boxes\"].data.cpu().numpy()\n",
        "        scores = outputs[i][\"scores\"].data.cpu().numpy()\n",
        "        labels = outputs[i][\"labels\"].data.cpu().numpy()\n",
        "\n",
        "        category={0: 'background',1:\"saito\", 2:\"ohnaka\",3:\"doi\",4:'sugai',5:'suzuki'}\n",
        "\n",
        "        boxes = boxes[scores >= 0.5].astype(np.int32)\n",
        "        scores = scores[scores >= 0.5]\n",
        "        image_id = image_ids[i]\n",
        "\n",
        "        for i, box in enumerate(boxes):\n",
        "            draw = ImageDraw.Draw(image)\n",
        "            label = category[labels[i]]\n",
        "            draw.rectangle([(box[0], box[1]), (box[2], box[3])], outline=\"red\", width=3)\n",
        "\n",
        "            # ラベルの表示\n",
        "            from PIL import Image, ImageDraw, ImageFont \n",
        "            # fnt = ImageFont.truetype('/content/mplus-1c-black.ttf', 20)\n",
        "            # fnt = ImageFont.truetype(\"arial.ttf\", 10)#40\n",
        "            # text_w, text_h = fnt.getsize(label)\n",
        "            # # draw.rectangle([box[0], box[1], box[0]+text_w, box[1]+text_h], fill=\"red\")\n",
        "            # draw.text((box[0], box[1]), label, font=fnt, fill='white')\n",
        "            draw.text((box[0], box[1]), label, fill='white')\n",
        "            print(label)\n",
        "\n",
        "\n",
        "        fig, ax = plt.subplots(1, 1)\n",
        "        ax.imshow(np.array(image))\n",
        "\n",
        "    plt.show()\n",
        "    print(label)\n",
        "\n",
        "\n",
        "show(val_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "rdswXBWPAwBg",
        "outputId": "4c2f3556-abea-4252-d3e4-ef1bb497efea"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-1c9cc1db1681>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m \u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'val_dataloader' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cRSYLM79AwOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRZpVLVETWST"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}